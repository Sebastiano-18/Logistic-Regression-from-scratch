# Logistic Regression From Scratch
## PROJECT OVERVIEW
This project implements Logistic Regression from scratch using NumPy (without scikit-learnâ€™s built-in model).
It demonstrates how logistic regression works under the hood with gradient descent, sigmoid function, and binary cross-entropy loss.

---
## ğŸš€ Project Structure
logistic-regression-from-scratch/
â”‚â”€â”€ .venv/ # Python Virtual Enviroment
â”‚â”€â”€ src/
    â””â”€â”€LogisticRegressionFromScratch.py # Python script
â”‚â”€â”€README.md
â”‚â”€â”€requirements.txt
â”‚â”€â”€LICENSE

---

## âš™ï¸ Features

- Implements logistic regression without external ML libraries.

- Uses gradient descent for optimization.

- Works for binary classification tasks.

- Includes example with a synthetic dataset (using sklearn.datasets.make_classification).
---
## ğŸ§‘â€ğŸ’» How to Run
1. Clone this repository:
```bash
git clone https://github.com/Sebastiano-18/Logistic-Regression-from-scratch.git
cd LogisticRegression-from-scratch
```
2. Install dependencies
```python
pip install numpy scikit-learn
```
3. Navigate to the src folder 
```bash
cd src
```
4. Run the model
```python
python LogisticRegressionFromScratch.py
```
--- 

## EXAMPLE OUTPUT
```yaml
Logistic Regression Accuracy: 0.83
```
---
## ğŸ“– Learning Objectives

- Understand how logistic regression works internally.

- Learn how to implement sigmoid function, loss function, and gradient descent manually.

- Gain intuition behind classification models
---
## ğŸ“œ License

This project is licensed under the MIT License.
