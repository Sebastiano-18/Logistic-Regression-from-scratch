# Logistic Regression From Scratch
## PROJECT OVERVIEW
This project implements Logistic Regression from scratch using NumPy (without scikit-learn’s built-in model).
It demonstrates how logistic regression works under the hood with gradient descent, sigmoid function, and binary cross-entropy loss.

---
## 🚀 Project Structure
logistic-regression-from-scratch/
│── .venv/ # Python Virtual Enviroment
│── src/
    └──LogisticRegressionFromScratch.py # Python script
│──README.md
│──requirements.txt
│──LICENSE

---

## ⚙️ Features

- Implements logistic regression without external ML libraries.

- Uses gradient descent for optimization.

- Works for binary classification tasks.

- Includes example with a synthetic dataset (using sklearn.datasets.make_classification).
---
## 🧑‍💻 How to Run
1. Clone this repository:
```bash
git clone https://github.com/Sebastiano-18/Logistic-Regression-from-scratch.git
cd LogisticRegression-from-scratch
```
2. Install dependencies
```python
pip install numpy scikit-learn
```
3. Navigate to the src folder 
```bash
cd src
```
4. Run the model
```python
python LogisticRegressionFromScratch.py
```
--- 

## EXAMPLE OUTPUT
```yaml
Logistic Regression Accuracy: 0.83
```
---
## 📖 Learning Objectives

- Understand how logistic regression works internally.

- Learn how to implement sigmoid function, loss function, and gradient descent manually.

- Gain intuition behind classification models
---
## 📜 License

This project is licensed under the MIT License.
